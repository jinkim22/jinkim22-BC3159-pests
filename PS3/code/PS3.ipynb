{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# COMS BC 3159 - S23\n",
        "# PS3: Trajectory Optimization\n",
        "* Due: 11:59pm, Friday March 10th\n",
        "\n",
        "# Written Assignment (14 points)\n",
        "\n",
        "Please go to the PDF in the written folder for the written instructions.\n",
        "\n",
        "# Coding Assignment (26 points)\n",
        "**You must submit to gradescope to get credit for the assignment --- make sure you submit the required files before the deadline!**\n",
        "\n",
        "**NOTE: You need to install some python pacakges `pip install -r requirements.txt`**\n",
        "\n",
        "**Files in this assignment:**\n",
        "`pendulum.py`   Defines a series of (very useful) helper functions related to the robot (the pendulum) we are working with.\n",
        "                You will need to finish some of the implementation here (and thus submit to Gradescope for Autograding).\n",
        "\n",
        "`util.py`       The main file you will edit and implement helper functions (and thus submit to Gradescope for Autograding).\n",
        "\n",
        "`trajopt.py`    Defines the high level trajectory optimzation functions that call the helper functions in `util` and `pendulum` in order to solve trajopt problems. You DO NOT need to submit this file.\n",
        "\n",
        "`runPend.py`    Sets up some constants and calls the trajopt functions to run and graphically display the solve. You DO NOT need to submit this file.\n",
        "                \n",
        "                Usage is: -MAIN_SOLVER (-INNER_SOLVER) where\n",
        "                    * MAIN_SOLVER  = [iLQR, SQP]\n",
        "                    * INNER_SOLVER = [CG, INV]"
      ],
      "metadata": {
        "id": "hmycZkiTLdD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install \"pygame>2.1\""
      ],
      "metadata": {
        "id": "4bxuiifZMQeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install \"numpy>1.23\" \"scipy>1.9\"\n"
      ],
      "metadata": {
        "id": "GVUl-7k9MTNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taylor Approximations of Dynamics and Cost Functions (7 Points)\n",
        "\n",
        "For this part of the problem we'll be working in the `pendulum.py` file and we'll be implementing a few dynamics and cost helper functions that we'll use in the rest of the assignemnt.\n",
        "\n",
        "Functions to update and their points:\n",
        "* `next_state` 2 points\n",
        "* `next_state_gradient` 2 points\n",
        "* `cost_value` 1 point\n",
        "* `cost_gradient` 1 point\n",
        "* `cost_hessian` 1 point\n",
        "\n",
        "We'll begin by converting the pendulum physics functions which compute acceleration (`dynamics`) and its gradient (`dynamics_gradient`) into `next_state` and `next_state_gradient` functions through the use of Euler integration. Recall from class that Euler integation adds a small amount of acceleration and velocity to the original position and velocity:\n",
        "```\n",
        "`[q', qd'] = [q, qd] + dt * [qd, qdd]`\n",
        "```\n",
        "Also recall that the dynamics derivative matricies are:\n",
        "```\n",
        "             A = [[dq'/dq, dq'/dqd],    and B = [[dq/du],\n",
        "                  [dqd'/dq, dqd'/dqd]]           [dqd/du]]\n",
        "```\n",
        "\n",
        "Next we'll move onto the cost functions. Here we need to implement the cost value, gradient, and hessian. For this problem we are going to use the \"standard simple quadratic cost\":\n",
        "```\n",
        "0.5(x-xg)^TQ(x-xg) + 0.5u^TRu\n",
        "```\n",
        "As that outputs a scalar value the cost gradient and hessian therefore are of the form:\n",
        "```\n",
        "g = [dcost/dq, dcost/dqd, dcost/du]\n",
        "H = [[d^2cost/dq^2,   d^2cost/dq dqd, d^2cost/dq du], \n",
        "     [d^2cost/dqd dq, dcost/dqd^2,    d^2cost/dqd du],\n",
        "     [d^2cost/du dq,  dcost/du dqd,   d^2cost/du^2]]\n",
        "```\n",
        "\n",
        "Note that most things are of type [`np.array`](https://numpy.org/doc/stable/user/quickstart.html) which hopefully should simplify your linear algebra and there are a few more hints left in the code comments! Also, make sure to take into account both the states and the controls!"
      ],
      "metadata": {
        "id": "ePXa9lBdLlAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sin, cos, pi\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "class Pendulum():\n",
        "    def __init__(self, timestep = 0.15, gravity = 9.81, damping = 0.01, control_min = -5, control_max = 5, control_step = 0.25):\n",
        "        self.timestep = timestep\n",
        "        self.gravity = gravity\n",
        "        self.damping = damping\n",
        "        self.control_min = control_min\n",
        "        self.control_max = control_max\n",
        "        self.control_step = control_step\n",
        "        self.Q = None\n",
        "        self.R = None\n",
        "        self.QF = None\n",
        "        self.goal = None\n",
        "\n",
        "    ######################\n",
        "    #                    #\n",
        "    # High level helpers #\n",
        "    #                    #\n",
        "    ######################\n",
        "\n",
        "    # return the state and control size\n",
        "    def get_state_size(self):\n",
        "        return 2\n",
        "    def get_control_size(self):\n",
        "        return 1\n",
        "\n",
        "    # clamp the input n to the range [smallest, largest]\n",
        "    def clamp(self, n, smallest, largest): \n",
        "        return max(smallest, min(n, largest))\n",
        "\n",
        "    # ensure angles are between -pi and pi\n",
        "    def wrap_angles(self, angle):\n",
        "        upper_bound = pi\n",
        "        lower_bound = -pi\n",
        "        while (angle < lower_bound):\n",
        "            angle += 2*pi\n",
        "        while (angle > upper_bound):\n",
        "            angle -= 2*pi\n",
        "        return np.array(angle)\n",
        "\n",
        "    # compute the difference between two states making sure to wrap angles\n",
        "    def state_delta(self, state1, state2):\n",
        "        return np.array([self.wrap_angles(state1[0]-state2[0]), state1[1]-state2[1]])\n",
        "\n",
        "    #####################################################\n",
        "    #                                                   #\n",
        "    #  Helper functions you need to fill out start here #\n",
        "    #                                                   #\n",
        "    #####################################################\n",
        "\n",
        "    ######################\n",
        "    #                    #\n",
        "    #  Physics helpers   #\n",
        "    #                    #\n",
        "    ######################\n",
        "\n",
        "    # apply the physics of the pendulum to compute acceleration\n",
        "    def dynamics(self, x, u):\n",
        "        position = x[0]\n",
        "        velocity = x[1]\n",
        "        qdd = u - self.gravity*sin(position) - self.damping*velocity\n",
        "        return np.array(qdd)\n",
        "\n",
        "    # compute the gradient of applying physics of the pendulum to compute acceleration\n",
        "    def dynamics_gradient(self, x, u):\n",
        "        position = x[0]\n",
        "        velocity = x[1]\n",
        "        # qdd = u - self.gravity*sin(position) - self.damping*velocity\n",
        "        dqdd_dq = -self.gravity*cos(position)\n",
        "        dqdd_dqd = -self.damping\n",
        "        dqdd_du = 1\n",
        "        return np.array([dqdd_dq, dqdd_dqd, dqdd_du])\n",
        "\n",
        "    # compute the next state using euler integration\n",
        "    def next_state(self, x, u):\n",
        "        position = np.array(x[0])\n",
        "        velocity = np.array(x[1])\n",
        "\n",
        "        # first compute acceleration using dynamics\n",
        "        # note: in this case we also clamp the input to control_min/max\n",
        "        #       to avoid unrealistic steps (this can be safely ignored in the gradient)\n",
        "        u_clamp = self.clamp(u, self.control_min, self.control_max)\n",
        "        acceleration = self.dynamics(x,u_clamp)\n",
        "\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Euler integrator [q', qd'] = [q, qd] + dt * [qd, qdd]\n",
        "        # note: make sure to wrap_angles where appropriate\n",
        "        #\n",
        "        return np.array([0,0])\n",
        "\n",
        "    # compute the gradient of the next state function using euler integration\n",
        "    def next_state_gradient(self, x, u):\n",
        "        position = x[0]\n",
        "        velocity = x[1]\n",
        "        A = np.array([[0, 0], [0, 0]])\n",
        "        B = np.array([[0], [0]])\n",
        "\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Euler integrator [q', qd'] = [q, qd] + dt * [qd, qdd]\n",
        "        # Return the partial derivative matricies:\n",
        "        #     A = [[dq'/dq, dq'/dqd],    and B = [[dq/du],\n",
        "        #          [dqd'/dq, dqd'/dqd]]           [dqd/du]]\n",
        "        #       \n",
        "        #\n",
        "        return A, B\n",
        "\n",
        "\n",
        "    ######################\n",
        "    #                    #\n",
        "    #    Cost helpers    #\n",
        "    #                    #\n",
        "    ######################\n",
        "\n",
        "    def set_Q(self, Q):\n",
        "        self.Q = Q\n",
        "    def set_R(self, R):\n",
        "        self.R = R\n",
        "    def set_QF(self, QF):\n",
        "        self.QF = QF\n",
        "    def set_goal(self, goal):\n",
        "        self.goal = goal\n",
        "\n",
        "    # compute the cost of the form 0.5(x-xg)^TQ(x-xg) + 0.5u^TRu\n",
        "    # note that if u=None then it is the final state and there is no control (use QF)\n",
        "    def cost_value(self, x, u = None):\n",
        "        cost = 0\n",
        "        # first compute the error between the current state and the goal\n",
        "        delta = self.state_delta(x, self.goal)\n",
        "        # then compute the cost for that error\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # hint: np.matmul may be useful!\n",
        "        return 0\n",
        "\n",
        "    # compute the gradient of the cost of the form 0.5(x-xg)^TQ(x-xg) + 0.5u^TRu\n",
        "    # note that if u=None then it is the final state and there is no control (use QF)\n",
        "    #\n",
        "    # return the vector [dcost/dq, dcost/dqd, dcost/du]\n",
        "    def cost_gradient(self, x, u = None):\n",
        "        grad = []\n",
        "        # first compute the error between the current state and the goal\n",
        "        delta = self.state_delta(x, self.goal)\n",
        "        # then compute the cost gradient with respect to the state\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        if u is not None:\n",
        "            return np.array([0,0,0])\n",
        "        else:\n",
        "            return np.array([0,0])\n",
        "\n",
        "    # compute the hessian of the cost of the form 0.5(x-xg)^TQ(x-xg) + 0.5u^TRu\n",
        "    # note that if u=None then it is the final state and there is no control (use QF)\n",
        "    #\n",
        "    # return the matrix [[d^2cost/dq^2,   d^2cost/dq dqd, d^2cost/dq du], \n",
        "    #                    [d^2cost/dqd dq, dcost/dqd^2,    d^2cost/dqd du],\n",
        "    #                    [d^2cost/du dq,  dcost/du dqd,   d^2cost/du^2]]\n",
        "    #\n",
        "    # Hint: you may find the block_diag helper function helpful! (But you don't need to use it)\n",
        "    #\n",
        "    def cost_hessian(self, x, u = None):\n",
        "        H = [[]]\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # hint: if u is None then you only need the hessian with respect to q, qd\n",
        "        #\n",
        "        if u is not None:\n",
        "            return np.zeros((3,3))\n",
        "        else:\n",
        "            return np.zeros((2,2))\n",
        "\n",
        "    def cost_gradient_hessian(self, x, u = None):\n",
        "        return self.cost_hessian(x,u), self.cost_gradient(x,u)\n",
        "\n",
        "    def block_diag(self, *arrs):\n",
        "        \"\"\"Create a block diagonal matrix from the provided arrays.\n",
        "\n",
        "        Given the inputs `A`, `B` and `C`, the output will have these\n",
        "        arrays arranged on the diagonal::\n",
        "\n",
        "            [[A, 0, 0],\n",
        "             [0, B, 0],\n",
        "             [0, 0, C]]\n",
        "\n",
        "        If all the input arrays are square, the output is known as a\n",
        "        block diagonal matrix.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        A, B, C, ... : array-like, up to 2D\n",
        "            Input arrays.  A 1D array or array-like sequence with length n is\n",
        "            treated as a 2D array with shape (1,n).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        D : ndarray\n",
        "            Array with `A`, `B`, `C`, ... on the diagonal.  `D` has the\n",
        "            same dtype as `A`.\n",
        "\n",
        "        References\n",
        "        ----------\n",
        "        .. [1] Wikipedia, \"Block matrix\",\n",
        "               http://en.wikipedia.org/wiki/Block_diagonal_matrix\n",
        "\n",
        "        Examples\n",
        "        --------\n",
        "        >>> A = [[1, 0],\n",
        "        ...      [0, 1]]\n",
        "        >>> B = [[3, 4, 5],\n",
        "        ...      [6, 7, 8]]\n",
        "        >>> C = [[7]]\n",
        "        >>> print(block_diag(A, B, C))\n",
        "        [[1 0 0 0 0 0]\n",
        "         [0 1 0 0 0 0]\n",
        "         [0 0 3 4 5 0]\n",
        "         [0 0 6 7 8 0]\n",
        "         [0 0 0 0 0 7]]\n",
        "        >>> block_diag(1.0, [2, 3], [[4, 5], [6, 7]])\n",
        "        array([[ 1.,  0.,  0.,  0.,  0.],\n",
        "               [ 0.,  2.,  3.,  0.,  0.],\n",
        "               [ 0.,  0.,  0.,  4.,  5.],\n",
        "               [ 0.,  0.,  0.,  6.,  7.]])\n",
        "\n",
        "        \"\"\"\n",
        "        if arrs == ():\n",
        "            arrs = ([],)\n",
        "        arrs = [np.atleast_2d(a) for a in arrs]\n",
        "\n",
        "        bad_args = [k for k in range(len(arrs)) if arrs[k].ndim > 2]\n",
        "        if bad_args:\n",
        "            raise ValueError(\"arguments in the following positions have dimension \"\n",
        "                                \"greater than 2: %s\" % bad_args) \n",
        "\n",
        "        shapes = np.array([a.shape for a in arrs])\n",
        "        out = np.zeros(np.sum(shapes, axis=0), dtype=arrs[0].dtype)\n",
        "\n",
        "        r, c = 0, 0\n",
        "        for i, (rr, cc) in enumerate(shapes):\n",
        "            out[r:r + rr, c:c + cc] = arrs[i]\n",
        "            r += rr\n",
        "            c += cc\n",
        "        return out"
      ],
      "metadata": {
        "id": "TWpNugJULpSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing and Solving KKT Systems (10 Points) and DDP Algorithm (9 points)\n",
        "### Constructing and Solving KKT Systems (10 Points)\n",
        "\n",
        "Now that we have built a full pendulum object with integrators and cost functions we can use that to build up and solve KKT systems using sucessive quadratic programming! All functions for this section (and the next DDP section) can be found in `util.py` and will be helper functions called by the functions in `trajopt.py`.\n",
        "\n",
        "Functions to update and their points:\n",
        "* `compute_total_cost` 1 point\n",
        "* `compute_total_constraint_violation` 2 point\n",
        "* `construct_KKT_system_blocks` 4 points\n",
        "* `assemble_KTT_system` 1 point\n",
        "*  `compute_merit_value` 1 point\n",
        "* `sqp_line_search_criteria` 1 point\n",
        "\n",
        "### Part 1: Helpers\n",
        "\n",
        "We'll start by setting up some real helper functions that build directly off of the previous section.\n",
        "* `compute_total_cost`: simply sums the cost across each timestep along the trajectory leveraging the cost functions your wrote in the previous section.\n",
        "* `compute_total_constraint_violation`: similarly sums up the constraint error. In our case this is simply the dynamics constraints along the trajecotory as well as the initial state constraint (`x0 = xs`). Please use the [L1 norm](https://montjoile.medium.com/l0-norm-l1-norm-l2-norm-l-infinity-norm-7a7d18a4f40c) here (aka absolute sum).\n",
        "\n",
        "### Part 2: Setting up the KKT System\n",
        "\n",
        "`construct_KKT_system_blocks`: Now that we have those helper functions in place lets set up the KKT system. This is the big part of this section. Here we want to walk through the states and controls along the trajectory and build the full `G, g, C, c` matricies. Note that in this case `G` is the cost Hessian for the whole trajectory, `g` is the cost gradient, `C` is the constraint gradient, and `c` is the constraint value. Also note that we assume the state/control/lambda ordering discussed in class. That is:\n",
        "```\n",
        "[x_0, u_0, x_1, u_1 ... u_{N-1}, x_N, \\lambda_0, \\lamnbda_1 ... \\lamnbda_N]^T\n",
        "```\n",
        "*Hint: what is the sparsity pattern you expect in those matricies?*\n",
        "\n",
        "`assemble_KTT_system`: Now that we have set up the KKT system blocks we need to form it into the full KKT system!\n",
        "```\n",
        "[[G, C^T],  *  [[xu],       =  [[-g],   <--->   KKT * xul = kkt\n",
        " [C, 0  ]]      [\\lambda]]      [c]]\n",
        "```\n",
        "\n",
        "### Part 3: Solving the KKT System\n",
        "\n",
        "Now that we have the problem steup we need to use sequential quadratic programming to continously solve QPs. But, we need to be careful and apply a line search to make sure we are taking good steps toward the goal! Since this is a constrained optimization problem we need to balance primal optimiality (finding the minimum of the cost function) and dual feasibility (finding a solution that doens't violate the constraints).\n",
        "\n",
        "`compute_merit_value`: we are going to go about doing this by forming what is called a \"merit function.\" This function will be the function we line search over and it will be our guide of how to balance the optimality and feasibility of our solution. We will use the standard L1 merit function (Nocedal and Wright 15.4) where:\n",
        "```\n",
        "merit = cost_value + \\mu * |constaint_value|\n",
        "```\n",
        "\n",
        "`sqp_line_search_criteria`: Finally, we'll evaluate the new trajectory as compared to the old trajectory and make sure we are improving in terms of making a sufficient decrease in both cost and constraint according to our merit function. \n",
        "\n",
        "*Hint: this one is simpler than you may think.*\n",
        "\n",
        "### Part 4 - Explore\n",
        "Now that you have a working SQP implementation run \n",
        "```\n",
        "python3 runPend.py -SQP\n",
        "```\n",
        "What happens? Does the trajectory go all the way to the goal? Does the trajectory always look dynamically feasible? Check the terminal output to see the cost function and constraint violations at each iteration. If you change the parameters for the cost function by adjusting `Q` and `R` in that file what happens? Play around with it a little bit. Hopefully it will give you a little better intuition for what the math is doing! You can also switch between using the standard matrix inverse solution of the KKT system to using a conjugate gradient verison. Simply pass in `-CG` or `-INV` at the end of the line above and you will switch between using the two. Can you tell a difference?\n",
        "\n",
        "### DDP Algorithm (9 points)\n",
        "\n",
        "In this section, you'll be implementing the DDP algorithm (in particular the iLQR variant). Your goal will be to implement several functions in `util.py` to successfully optimize paths under a cost function. We'll be leveraging all of the work we have done before to help setup the problem and again the main loop code is in `trajopt.py`.\n",
        "\n",
        "Functions that should be filled in for full credit in the `util.py` file are:\n",
        "* `initialize_CTG`            - 1 point\n",
        "* `backpropogate_CTG`         - 2 points\n",
        "* `compute_du_K`              - 1 point\n",
        "* `compute_new_CTG`           - 1 point\n",
        "* `backward_pass_iterate`     - 1 points\n",
        "* `compute_control_update`    - 1 point\n",
        "* `rollout_trajectory`        - 1 point\n",
        "* `ilqr_line_search_criteria` - 1 point\n",
        "\n",
        "### Part 1 - The Backward Pass\n",
        "We first compute the feedback control update along the backward pass using the math from the lecture slides (again this is not something you should memorize but it is helpful to understand how its working). Be careful with the sizes of various items and note that you will likely need to slice into items to get the subparts you are looking for.\n",
        "\n",
        "`initialize_CTG`: We start by setting up the initial quadratic approximation of the cost-to-go (aka negative reward / value function) at the final state. Hint: what is the possible best cost you can have when you are at the last state? What is a quadratic approximation of that?\n",
        "\n",
        "`backpropogate_CTG`: We now need to compute the CTG update at the previous state using our linear approximation of the dynamics and our quadratic approximation of the cost at that state and of the cost-to-go at the next state. To do this we will use the iLQR version of the math from the lecture slides. Also note that most things are numpy arrays and so the [np.matmul](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html) function will make your life a lot easier!\n",
        "\n",
        "```\n",
        "Qxx = lxx + fx^T V'xx fx\n",
        "Quu = luu + fu^T V'xx fu\n",
        "Qxu = lxu + fx^T V'xx fu\n",
        "Qx = lx + fx^T V'x\n",
        "Qu = lu + fu^T V'x\n",
        "```\n",
        "\n",
        "`compute_du_K`and `compute_new_CTG` Following that you'll need to use those outputs to construct K, du, and the new estimate of the cost-to-go Vxx, Vx again using the math from the lecture slides (see image below) and again most things are numpy arrays!\n",
        "\n",
        "```\n",
        "\\delta u = = -Quu^{-1} (Qux \\delta x + Qu) = K \\delta x + du\n",
        "Vx = Qx - Qxu du\n",
        "Vxx = Qxx - Qxu K\n",
        "```\n",
        "\n",
        "* `backward_pass_iterate` Finally we'll put that all together and solve a full backwards pass iterate. That is, given `A, B, H, g` -- the cost and dynaics gradients and the cost Hessian --  as well as `Vxx_kp1, Vx_kp1` -- the next states CTG gradient and Hessian -- how can we output `duk, Kk, Vxx, Vx` -- the feedforward and feedback update to the controls and the currrent gradient and Hessian of the CTG.\n",
        "\n",
        "*Hint: you mostly just need to call the previous few functions!*\n",
        "\n",
        "### Part 3 - The Forward Pass\n",
        "Finally, you'll want to compute the control updates in the forward pass based on the feedback controller you computed in the backward pass!\n",
        "\n",
        "`compute_control_update`: Here we want to compute the change in a single control we want to apply at a single state. Remember that we have both a feedforward (du) term and a feedback (K) term. You'll also want to implement the line search version of the control update!\n",
        "\n",
        "`rollout_trajectory`: Now you'll want to use that function to rollout a full new trajectory for a given line search iterate.\n",
        "\n",
        "`ilqr_line_search_criteria`: Finally, you'll want to return a flag indicating whether that newly rolled out trajectory should be accepted or rejected. Remember in iLQR the constraints are implicit in the rollout, so we only need to worry about making sure we have improved in terms of optimality (cost).\n",
        "\n",
        "*Hint: this one is simpler than you may think.*\n",
        "\n",
        "### Part 4 - Explore\n",
        "Now that you have a working DDP implementation run the `runPend.py` file. What happens? How does this work as compared to the SQP algorithm? Is it better? Worse? Slower? Faster? Does the trajectory go all the way to the goal? If you change the parameters for the cost function by adjusting `Q` and `R` in that file what happens? Play around with it a little bit. Hopefully it will give you a little better intuition for what the math is doing!"
      ],
      "metadata": {
        "id": "Wzu9xzTSLnVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "class Util:\n",
        "    def __init__(self, robot_object):\n",
        "        self.robot_object = robot_object\n",
        "\n",
        "    #####################################################\n",
        "    #                                                   #\n",
        "    #  Helper functions you need to fill out start here #\n",
        "    #                                                   #\n",
        "    #####################################################\n",
        "\n",
        "    #####################################################\n",
        "    #                                                   #\n",
        "    #    Initialization and Taylor Expansion Helpers    #\n",
        "    #                                                   #\n",
        "    #####################################################\n",
        "\n",
        "    # Compute the total cost along the trajectory\n",
        "    def compute_total_cost(self, x, u, nx, nu, N):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: You may want to use the helper functions in the robot_object!\n",
        "        #\n",
        "        J = 0\n",
        "        return J\n",
        "\n",
        "    # compute the total constraint error\n",
        "    def compute_total_constraint_violation(self, x, u, xs, nx, nu, N):\n",
        "        # I'll start us off with th initial state constraint\n",
        "        x_err = x[:,0] - xs\n",
        "        const = np.linalg.norm(x_err, ord=1)\n",
        "        # then we need to find all of the dynamics errors\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        #\n",
        "        return const\n",
        "\n",
        "    # compute the dynamics and cost gradient and hessians\n",
        "    def compute_approximation(self, xk, uk, nx, nu, k):\n",
        "        Hk, gk = self.robot_object.cost_gradient_hessian(xk, uk)\n",
        "        Ak, Bk = self.robot_object.next_state_gradient(xk, uk)\n",
        "        return Ak, Bk, Hk, gk\n",
        "\n",
        "    #####################################################\n",
        "    #                                                   #\n",
        "    #              KKT System Helpers                   #\n",
        "    #                                                   #\n",
        "    #####################################################\n",
        "    \n",
        "    # form the blocks of the KKT system matrix and vector\n",
        "    def construct_KKT_system_blocks(self, x, u, xs, nx, nu, N):\n",
        "        total_states = nx*N\n",
        "        total_controls = nu*(N-1)\n",
        "        total_states_controls = total_states + total_controls\n",
        "\n",
        "        # placeholders of the right size for the blocks you need to compute\n",
        "        G = np.zeros((total_states_controls, total_states_controls))\n",
        "        g = np.zeros((total_states_controls, 1))\n",
        "        C = np.zeros((total_states, total_states_controls)) # note for our setup constraints are equal to states\n",
        "        c = np.zeros((total_states, 1))\n",
        "\n",
        "        n = nx + nu\n",
        "\n",
        "        # filling in the initial constraint gradient and value for you!\n",
        "        C[0:nx, 0:nx] = np.eye(nx)\n",
        "        c[0:nx, 0] = x[:,0] - xs\n",
        "\n",
        "        # now compute all the cost gradients and hessians and the rest of the constraint gradients\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: Don't forget about the final cost gradient / hessian!\n",
        "        #\n",
        "\n",
        "        return G, g, C, c\n",
        "\n",
        "    # form the main KKT system matrix and vector from its blocks\n",
        "    def assemble_KTT_system(self, G, g, C, c, nx, nu, N):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: h and v stack things up!\n",
        "        #\n",
        "        KKTMatrix = None\n",
        "        KKTVector = None\n",
        "        return KKTMatrix, KKTVector\n",
        "\n",
        "    # compute the merit function value along a trajectory\n",
        "    def compute_merit_value(self, x, u, xs, mu, nx, nu, N):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: how are we balancing optimality and feasability?\n",
        "        #  \n",
        "        J = 0\n",
        "        const = 0\n",
        "        merit = 0\n",
        "        return J, const, merit\n",
        "\n",
        "    # line search flag for the SQP algorithm\n",
        "    def sqp_line_search_criteria(self, x_new, u_new, J_new, const_new, merit_new, x, u, J, const, merit, nx, nu, N):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: did things get better?\n",
        "        #  \n",
        "        return False\n",
        "\n",
        "    #####################################################\n",
        "    #                                                   #\n",
        "    #            iLQR Backward Pass Helpers             #\n",
        "    #                                                   #\n",
        "    #####################################################\n",
        "\n",
        "    # what is the quadratic approximation of the optimal solution\n",
        "    # from the perspective of the last state?\n",
        "    def initialize_CTG(self, x, nx, k):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: You may want to use the helper functions in the robot_object!\n",
        "        #\n",
        "        Vxx = None\n",
        "        Vx = None\n",
        "        return Vxx, Vx\n",
        "\n",
        "    # compute the quadratic estimate one state back along the trajectory\n",
        "    def backpropogate_CTG(self, A, B, H, g, Vxx, Vx, nx, nu, k):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: A = fx, B = fu, H = Jww, g = Jw where w is x or u!\n",
        "        # Hint2: Everything is a np.array and np.matmul may be helpful!\n",
        "        #\n",
        "        Hxx = None\n",
        "        Huu = None\n",
        "        Hux = None\n",
        "        gx = None\n",
        "        gu = None\n",
        "        return Hxx, Hux, Huu, gx, gu\n",
        "\n",
        "    # given the above computation what is the feedback and feedforward update?\n",
        "    def compute_kappa_K(self, Hxx, Hux, Huu, gx, gu, HuuInv, nx, nu, N):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: Everything is a np.array and np.matmul may be helpful!\n",
        "        #\n",
        "        K = None\n",
        "        kappa = None\n",
        "        return kappa, K\n",
        "\n",
        "    # given all that above what is the new CTG estimate at this state?\n",
        "    def compute_new_CTG(self, Hxx, Hux, Huu, gx, gu, HuuInv, kappa, K, nx, nu, N):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: Everything is a np.array and np.matmul may be helpful!\n",
        "        #\n",
        "        Vxx = None\n",
        "        Vx = None\n",
        "        return Vxx, Vx\n",
        "\n",
        "    # put most of the above backward pass functions together and get from\n",
        "    # the inputs to return the current kappa, K, Vxx, Vx\n",
        "    def backward_pass_iterate(self, A, B, H, g, Vxx_kp1, Vx_kp1, nx, nu, k):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: you mostly just need to call the helper functions defined above!\n",
        "        #       and np.linalg.inv may be helpful!\n",
        "        #\n",
        "        kappak = None\n",
        "        Kk = None\n",
        "        Vxx = None\n",
        "        Vx = None\n",
        "        return kappak, Kk, Vxx, Vx\n",
        "\n",
        "    #####################################################\n",
        "    #                                                   #\n",
        "    #           iLQR Forward Pass Helpers               #\n",
        "    #                                                   #\n",
        "    #####################################################\n",
        "\n",
        "    # return u_new based on the current x_new, k, kappa, alpha, and original x\n",
        "    def compute_control_update(self, x, x_new, K, kappa, alpha, nx, nu, N):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: You may want to use the helper functions in the robot_object!\n",
        "        # Hint2: Everything is a np.array and np.matmul may be helpful!\n",
        "        # Hint3: We are computing the UPDATE to the controls\n",
        "        #\n",
        "        delta = self.robot_object.state_delta(x_new, x)\n",
        "        return 0\n",
        "\n",
        "    # rollout the full trajectory to produce x_new, u_new based on\n",
        "    # x, u (the original trajectory), as well as K, kappa, alpha (the updates)\n",
        "    def rollout_trajectory(self, x, u, K, kappa, alpha, nx, nu, N):\n",
        "        x_new = copy.deepcopy(x)\n",
        "        u_new = copy.deepcopy(u)\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: You may want to use the helper functions in the robot_object and in util!\n",
        "        #        \n",
        "        return x_new, u_new\n",
        "\n",
        "    # make sure things got better\n",
        "    def ilqr_line_search_criteria(self, x_new, u_new, J_new, x, u, J, nx, nu, N):\n",
        "        #\n",
        "        # TODO\n",
        "        #\n",
        "        # Hint: did things get better?\n",
        "        #  \n",
        "        return False"
      ],
      "metadata": {
        "id": "6GNa5-cULe-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Solver and Runner Code\n",
        "`trajopt.py`    Defines the high level trajectory optimzation functions that call the helper functions in `util` and `pendulum` in order to solve trajopt problems. You DO NOT need to submit this file.\n",
        "\n",
        "`runPend.py`    Sets up some constants and calls the trajopt functions to run and graphically display the solve. You DO NOT need to submit this file.\n",
        "                \n",
        "                Usage is: -MAIN_SOLVER (-INNER_SOLVER) where\n",
        "                    * MAIN_SOLVER  = [iLQR, SQP]\n",
        "                    * INNER_SOLVER = [CG, INV]"
      ],
      "metadata": {
        "id": "RFvU9rFmLx3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trajopt.py\n",
        "# This program runs the main algorithms built on top of your util functions\n",
        "# (Do not modify, but please read)\n",
        "#\n",
        "# Brian Plancher - Spring 2023\n",
        "# Adapted from code written by Rus Tedrake and Scott Kuindersma\n",
        "\n",
        "import sys, math, pygame, copy\n",
        "from pygame.locals import *\n",
        "from time import sleep\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "np.set_printoptions(precision=3) # so things print nicer\n",
        "\n",
        "class Trajopt:\n",
        "    def __init__(self, robot_object, start_node, goal_node, N, XMAX_MIN, YMAX_MIN, \\\n",
        "                       MAX_ITER = 100, EXIT_TOL = 1e-3, ALPHA_FACTOR = 0.5, ALPHA_MIN = 1e-4, MU = 5):\n",
        "        self.robot_object = robot_object # the robot_object with physics and cost functions\n",
        "        self.MAX_ITER = MAX_ITER         # total ddp loops to try\n",
        "        self.EXIT_TOL = EXIT_TOL         # This is the convergence criterion. We will declare success when the trajectory\n",
        "                                         # is updated by a norm of less that 1e-4. DO NOT MODIFY.\n",
        "        self.N = N                       # Number of nodes in a trajectory\n",
        "        self.start_node = start_node\n",
        "        self.goal_node = goal_node\n",
        "        self.util = Util(self.robot_object)\n",
        "        self.XMAX_MIN = XMAX_MIN         # max for drawing locically\n",
        "        self.YMAX_MIN = YMAX_MIN         # max for drawing locically\n",
        "        self.canvas_max = 640            # max for drawing pixels\n",
        "        # set global line search parameters\n",
        "        self.alpha_factor = ALPHA_FACTOR # how much to reduce alpha by each deeper search\n",
        "        self.alpha_min = ALPHA_MIN       # minimum alpha to try\n",
        "        self.mu = MU                     # merit function weighting        \n",
        "\n",
        "    def draw_circle(self, node, size, color):\n",
        "        percent_x = (node[0] + self.XMAX_MIN) / 2 / self.XMAX_MIN\n",
        "        percent_y = (node[1] + self.YMAX_MIN) / 2 / self.YMAX_MIN\n",
        "    \n",
        "        scaled_x = int(self.canvas_max*percent_x)\n",
        "        scaled_y = int(self.canvas_max*percent_y)    \n",
        "\n",
        "        pygame.draw.circle(self.screen, color, (scaled_x, scaled_y), size)\n",
        "\n",
        "    def draw_line(self, node1, node2, color):\n",
        "        percent_x1 = (node1[0] + self.XMAX_MIN) / 2 / self.XMAX_MIN\n",
        "        percent_y1 = (node1[1] + self.YMAX_MIN) / 2 / self.YMAX_MIN\n",
        "        percent_x2 = (node2[0] + self.XMAX_MIN) / 2 / self.XMAX_MIN\n",
        "        percent_y2 = (node2[1] + self.YMAX_MIN) / 2 / self.YMAX_MIN\n",
        "    \n",
        "        scaled_x1 = int(self.canvas_max*percent_x1)\n",
        "        scaled_y1 = int(self.canvas_max*percent_y1)\n",
        "        scaled_x2 = int(self.canvas_max*percent_x2)\n",
        "        scaled_y2 = int(self.canvas_max*percent_y2)\n",
        "\n",
        "        # check if angle wrapping (and don't draw lines across the screen)\n",
        "        if node1[0] - node2[0] > math.pi:\n",
        "            pass\n",
        "        elif node1[0] - node2[0] < -math.pi:\n",
        "            pass\n",
        "        else:\n",
        "            pygame.draw.line(self.screen, color, (scaled_x2, scaled_y2), (scaled_x1, scaled_y1))\n",
        "\n",
        "    def init_screen(self):\n",
        "        # initialize and prepare screen\n",
        "        pygame.init()\n",
        "        self.screen = pygame.display.set_mode((self.canvas_max,self.canvas_max))\n",
        "        pygame.display.set_caption('PS3 - RRT')\n",
        "        black = 20, 20, 40\n",
        "        blue = 0, 0, 255\n",
        "        green = 0, 255, 0\n",
        "        self.screen.fill(black)\n",
        "        self.draw_circle(self.start_node, 5, blue)\n",
        "        self.draw_circle(self.goal_node, 5, green)\n",
        "        pygame.display.update()\n",
        "\n",
        "    def draw_trajectory(self, x):\n",
        "        white = 255, 240, 200\n",
        "        red = 255, 0, 0\n",
        "        self.draw_circle(x[:,0], 2, white)\n",
        "        for k in range(1,self.N):\n",
        "            self.draw_circle(x[:,k], 2, white)\n",
        "            self.draw_line(x[:,k-1], x[:,k], red)\n",
        "        pygame.display.update()\n",
        "        sleep(0.4)\n",
        "\n",
        "    def wait_to_exit(self, x, u, DISPLAY_MODE = True):\n",
        "        # if in test mode return the path\n",
        "        if not DISPLAY_MODE:\n",
        "            return x, u, K\n",
        "        # Else wait for the user to see the solution to exit\n",
        "        else:\n",
        "            while(1):\n",
        "                for e in pygame.event.get():\n",
        "                    if e.type == QUIT or (e.type == KEYUP and e.key == K_ESCAPE):\n",
        "                        sys.exit(\"Leaving because you requested it.\")\n",
        "\n",
        "\n",
        "    def solve(self, x, u, N, DISPLAY_MODE = False, MAIN_SOLVER = '-iLQR', INNER_SOLVER = '-CG'):\n",
        "        # start up the graphics\n",
        "        self.init_screen()\n",
        "\n",
        "        # get constants\n",
        "        nx = self.robot_object.get_state_size()\n",
        "        nu = self.robot_object.get_control_size()\n",
        "\n",
        "        # solve\n",
        "        error = False\n",
        "        if MAIN_SOLVER == '-iLQR':\n",
        "            self.iLQR(x, u, nx, nu, N, DISPLAY_MODE)\n",
        "        elif MAIN_SOLVER == '-SQP':\n",
        "            if INNER_SOLVER == '-CG':\n",
        "                self.SQP(x, u, nx, nu, N, DISPLAY_MODE, 1)\n",
        "            elif INNER_SOLVER == '-INV':\n",
        "                self.SQP(x, u, nx, nu, N, DISPLAY_MODE, 0)\n",
        "            else:\n",
        "                print(\"[!] ERROR: Invalid Inner Solver: \", INNER_SOLVER)\n",
        "                error = True\n",
        "        else:\n",
        "            print(\"[!] ERROR: Invalid Solver: \", MAIN_SOLVER)\n",
        "            error = True\n",
        "        return error\n",
        "\n",
        "\n",
        "    def SQP(self, x, u, nx, nu, N, DISPLAY_MODE = False, INNER_SOLVER = 0):\n",
        "        # compute initial merit function value\n",
        "        xs = copy.deepcopy(x[:,0])\n",
        "        J, const, merit = self.util.compute_merit_value(x, u, xs, self.mu, nx, nu, N)\n",
        "        J_prev = J\n",
        "        if DISPLAY_MODE:\n",
        "            print(\"Initial Cost: \", J)\n",
        "            print(\"Initial Constraint Violation: \", const)\n",
        "            print(\"Initial Merit Function: \", merit)\n",
        "\n",
        "        # start the main loop\n",
        "        iteration = 0\n",
        "        failed = False\n",
        "        while 1:\n",
        "\n",
        "            # construct the KKT system blocks\n",
        "            G, C, g, c = self.util.construct_KKT_system_blocks(x, u, xs, nx, nu, N)\n",
        "\n",
        "            # assemble into full KKT system\n",
        "            KKTMatrix, KKTVector = self.util.assemble_KTT_system(G, C, g, c, nx, nu, N)\n",
        "\n",
        "            # solve the KKT system\n",
        "            if INNER_SOLVER == 0: # backslash (standard matrix inverse / factorization)\n",
        "                dxul_new = np.linalg.solve(KKTMatrix,KKTVector)[:,0]\n",
        "            else: # conjugate gradient\n",
        "                dxul_new = sp.sparse.linalg.cg(KKTMatrix,KKTVector)[0]\n",
        "\n",
        "            # do line search to accept (or reject) the update\n",
        "            alpha = 1\n",
        "            while 1:\n",
        "                # unravel the update\n",
        "                x_new = copy.deepcopy(x)\n",
        "                u_new = copy.deepcopy(u)\n",
        "                for k in range(N-1):\n",
        "                    x_new[:,k] += alpha*dxul_new[(nx+nu)*k:(nx+nu)*k + nx]\n",
        "                    u_new[:,k] += alpha*dxul_new[(nx+nu)*k + nx:(nx+nu)*(k+1)]\n",
        "                x_new[:,N-1] += alpha*dxul_new[(nx+nu)*(N-1):(nx+nu)*(N-1) + nx]\n",
        "\n",
        "                # compute the cost, constraint violation, and merit function\n",
        "                J_new, const_new, merit_new = self.util.compute_merit_value(x_new, u_new, xs, self.mu, nx, nu, N)\n",
        "\n",
        "                # compute the line search criteria\n",
        "                flag = self.util.sqp_line_search_criteria(x_new, u_new, J_new, const_new, merit_new, x, u, J, const, merit, nx, nu, N)\n",
        "\n",
        "                if flag:\n",
        "                    J_prev = J\n",
        "                    x = x_new\n",
        "                    u = u_new\n",
        "                    J = J_new\n",
        "                    const = const_new\n",
        "                    merit = merit_new\n",
        "                    if DISPLAY_MODE:\n",
        "                        print(\"Iter[\", iteration, \"] Cost[\", np.round(J,4), \"], Constraint Violation[\", np.round(const,4), \"], \", \\\n",
        "                                                     \"mu [\", self.mu, \"], Merit Function[\", np.round(merit,4), \"] and x final:\")\n",
        "                        print(x[:,N-1])\n",
        "                        self.draw_trajectory(x)\n",
        "                    break\n",
        "\n",
        "                # failed try to continue the line search\n",
        "                elif alpha > self.alpha_min:\n",
        "                    alpha *= self.alpha_factor\n",
        "                    if DISPLAY_MODE:\n",
        "                        print(\"Deepening the line search\")\n",
        "                \n",
        "                # failed line search\n",
        "                else:\n",
        "                    if DISPLAY_MODE:\n",
        "                        print(\"Line search failed\")\n",
        "                    failed = True\n",
        "                    break\n",
        "\n",
        "            # Check for exit (or error)\n",
        "            if failed: # need double break to get out of both loops here if line search fails\n",
        "                break\n",
        "\n",
        "            delta_J = J_prev - J\n",
        "            if delta_J < self.EXIT_TOL:\n",
        "                if DISPLAY_MODE:\n",
        "                    print(\"Exiting for exit_tolerance\")\n",
        "                break\n",
        "            \n",
        "            if iteration == self.MAX_ITER - 1:\n",
        "                if DISPLAY_MODE:\n",
        "                    print(\"Exiting for max_iter\")\n",
        "                break\n",
        "            else:\n",
        "                iteration += 1\n",
        "\n",
        "        if DISPLAY_MODE:\n",
        "            print(\"Final Trajectory\")\n",
        "            print(x)\n",
        "            print(u)\n",
        "\n",
        "        self.wait_to_exit(x, u, DISPLAY_MODE)\n",
        "\n",
        "    def iLQR(self, x, u, nx, nu, N, DISPLAY_MODE = False):\n",
        "        \n",
        "        # allocate memory for things we will compute\n",
        "        kappa = np.zeros([nu,N-1])     # control updates\n",
        "        K = np.zeros((nu,nx,N-1))   # feedback gains\n",
        "\n",
        "        # compute initial cost\n",
        "        J = self.util.compute_total_cost(x, u, nx, nu, N)\n",
        "        J_prev = J\n",
        "        if DISPLAY_MODE:\n",
        "            print(\"Initial Cost: \", J)\n",
        "\n",
        "        # start the main loop\n",
        "        iteration = 0\n",
        "        failed = False\n",
        "        while 1:\n",
        "\n",
        "            # Do backwards pass to compute new control update and feedback gains: kappa and K\n",
        "            # start by initializing the cost to go\n",
        "            Vxx, Vx = self.util.initialize_CTG(x[:,N-1], nx, N) \n",
        "            for k in range(N-2,-1,-1):\n",
        "                # then compute the quadratic approximation at that point\n",
        "                A, B, H, g = self.util.compute_approximation(x[:,k], u[:,k], nx, nu, k)\n",
        "\n",
        "                # then compute the control update and new CTG estimates\n",
        "                kappak, Kk, Vxx, Vx = self.util.backward_pass_iterate(A, B, H, g, Vxx, Vx, nx, nu, k)\n",
        "\n",
        "                # save kappa and K for forward pass\n",
        "                kappa[:,k] = kappak.tolist()\n",
        "                K[:,:,k] = Kk.tolist()\n",
        "\n",
        "            # Do forwards pass to compute new x, u, J (with line search)\n",
        "            alpha = 1\n",
        "            while 1:\n",
        "                # rollout new trajectory\n",
        "                x_new, u_new = self.util.rollout_trajectory(x, u, K, kappa, alpha, nx, nu, N)\n",
        "\n",
        "                # compute new cost\n",
        "                J_new = self.util.compute_total_cost(x_new, u_new, nx, nu, N)\n",
        "                    \n",
        "                # simple line search criteria\n",
        "                flag = self.util.ilqr_line_search_criteria(x_new, u_new, J_new, x, u, J, nx, nu, N)\n",
        "\n",
        "                if flag:\n",
        "                    J_prev = J\n",
        "                    x = x_new\n",
        "                    u = u_new\n",
        "                    J = J_new\n",
        "                    if DISPLAY_MODE:\n",
        "                        print(\"Iteration[\", iteration, \"] with cost[\", round(J,4), \"] and x final:\")\n",
        "                        print(x[:,N-1])\n",
        "                        self.draw_trajectory(x)\n",
        "                    break\n",
        "\n",
        "                # failed try to continue the line search\n",
        "                elif alpha > self.alpha_min:\n",
        "                    alpha *= self.alpha_factor\n",
        "                    if DISPLAY_MODE:\n",
        "                        print(\"Deepening the line search\")\n",
        "                \n",
        "                # failed line search\n",
        "                else:\n",
        "                    if DISPLAY_MODE:\n",
        "                        print(\"Line search failed\")\n",
        "                    failed = True\n",
        "                    break\n",
        "\n",
        "            # Check for exit (or error)\n",
        "            if failed: # need double break to get out of both loops here if line search fails\n",
        "                break\n",
        "\n",
        "            delta_J = J_prev - J\n",
        "            if delta_J < self.EXIT_TOL:\n",
        "                if DISPLAY_MODE:\n",
        "                    print(\"Exiting for exit_tolerance\")\n",
        "                break\n",
        "            \n",
        "            if iteration == self.MAX_ITER - 1:\n",
        "                if DISPLAY_MODE:\n",
        "                    print(\"Exiting for max_iter\")\n",
        "                break\n",
        "            else:\n",
        "                iteration += 1\n",
        "\n",
        "        if DISPLAY_MODE:\n",
        "            print(\"Final Trajectory\")\n",
        "            print(x)\n",
        "            print(u)\n",
        "\n",
        "        self.wait_to_exit(x, u, DISPLAY_MODE)"
      ],
      "metadata": {
        "id": "I7yBHL0BLxGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tricking colab to run pygame per https://colab.research.google.com/drive/1xtiBrGeRHmXY3KSOixkZBf_rJIgBImJu?usp=sharing#scrollTo=7X42jJWlAuSl\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "import time \n",
        "import os, sys\n",
        "# set SDL to use the dummy NULL video driver, \n",
        "#   so it doesn't need a windowing system.\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
      ],
      "metadata": {
        "id": "ztdkGAlyMo6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import pi\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "XMAX_MIN = pi\n",
        "YMAX_MIN = 10\n",
        "\n",
        "X_START = [0,0]\n",
        "X_GOAL = [pi,0]\n",
        "\n",
        "# How did I get these numbers? A little intuition and a lot of guess and check.\n",
        "QF = np.array([[30,0],[0,10]])\n",
        "Q = np.array([[3,0],[0,1]])\n",
        "R = np.array([0.08])\n",
        "\n",
        "N = 32\n",
        "\n",
        "pend = Pendulum()\n",
        "pend.set_Q(Q)\n",
        "pend.set_R(R)\n",
        "pend.set_QF(QF)\n",
        "pend.set_goal(X_GOAL)\n",
        "\n",
        "x0 = np.zeros([pend.get_state_size(),N])\n",
        "u0 = np.zeros([pend.get_control_size(),N-1])\n",
        "\n",
        "trajopt_obj = Trajopt(pend, X_START, X_GOAL, N, XMAX_MIN, YMAX_MIN)"
      ],
      "metadata": {
        "id": "b9mmWM7AMLHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calls for Tests\n",
        "Note that only the text to command line will display -- even though we tricked the video driver it doesn't pop up the pygame window (you'll need to run it locally for the fun visualizaiton). **So you'll need to kill each cell with the stop button!**"
      ],
      "metadata": {
        "id": "nB75YqgDPVRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trajopt_obj.solve(x0, u0, N, True, '-SQP', '-INV')"
      ],
      "metadata": {
        "id": "tSvbKYVZMfom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trajopt_obj.solve(x0, u0, N, True, '-SQP', '-CG')"
      ],
      "metadata": {
        "id": "QUBr9xdFM8Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trajopt_obj.solve(x0, u0, N, True, '-iLQR')"
      ],
      "metadata": {
        "id": "a82NWOURNCNR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}